{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SfqPHdXiNas",
        "outputId": "71987988-2f0b-4ae3-aaf1-2fd6465660e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_from_gdrive(data_dir):\n",
        "  # Initialize an empty list to store the DataFrames\n",
        "  data_frames = []\n",
        "\n",
        "  # Loop through each .csv file in the directory\n",
        "  for dir in data_dir:\n",
        "    for file_name in os.listdir(dir):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(dir, file_name)\n",
        "\n",
        "            # Load the .csv file into a DataFrame\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Remove the first column\n",
        "            df = df.iloc[:, 4:]\n",
        "\n",
        "            df  = df.div(360)\n",
        "\n",
        "            df  = df.clip(upper =1,lower = -1)\n",
        "\n",
        "\n",
        "            # Append the DataFrame to the list\n",
        "            data_frames.append(df)\n",
        "\n",
        "  # Concatenate the DataFrames into a single DataFrame\n",
        "  combined_df = pd.concat(data_frames, axis=0, ignore_index=True)\n",
        "  return combined_df"
      ],
      "metadata": {
        "id": "cROH6bJ8iZPt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Normal']\n",
        "\n",
        "combined_df =  load_from_gdrive(data_dir)\n"
      ],
      "metadata": {
        "id": "htu7C0x1iaod"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ComplexVAEFFT(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, neurons, dropout_rate=0.5, weight_decay=0.01):\n",
        "        super(ComplexVAEFFT, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "              nn.Linear(input_size * 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons // 4, self.latent_size * 2)\n",
        "          )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "              nn.Linear(self.latent_size, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 4, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons, input_size * 2)\n",
        "          )\n",
        "\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply FFT to input\n",
        "        x_fft = torch.fft.fft(x)\n",
        "\n",
        "        # Separate real and imaginary parts\n",
        "        x_fft_real = x_fft.real\n",
        "        x_fft_imag = x_fft.imag\n",
        "        x_fft_separated = torch.cat((x_fft_real, x_fft_imag), dim=-1)\n",
        "\n",
        "        latent_params = self.encoder(x_fft_separated)\n",
        "        mu = latent_params[:, :self.latent_size]  # Use self.latent_size\n",
        "        logvar = latent_params[:, self.latent_size:]  # Use self.latent_size\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstruction_separated = self.decoder(z)\n",
        "\n",
        "        # Combine real and imaginary parts\n",
        "        reconstruction_real = reconstruction_separated[:, :input_size]\n",
        "        reconstruction_imag = reconstruction_separated[:, input_size:]\n",
        "        reconstruction = torch.complex(reconstruction_real, reconstruction_imag)\n",
        "\n",
        "        # Apply inverse FFT to output\n",
        "        reconstruction_ifft = torch.fft.ifft(reconstruction)\n",
        "\n",
        "        return reconstruction_ifft, mu, logvar\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "def complex_mse_loss(reconstruction, x):\n",
        "    # Compute MSE for real part\n",
        "    reconstruction_real = reconstruction.real\n",
        "    real_loss = nn.functional.mse_loss(reconstruction_real, x, reduction='sum')\n",
        "\n",
        "    # Compute MSE for imaginary part\n",
        "    if torch.is_complex(x):\n",
        "        x_imag = x.imag\n",
        "        reconstruction_imag = reconstruction.imag\n",
        "        imag_loss = nn.functional.mse_loss(reconstruction_imag, x_imag, reduction='sum')\n",
        "    else:\n",
        "        imag_loss = 0\n",
        "\n",
        "    return real_loss + imag_loss\n",
        "\n",
        "def vae_loss(reconstruction, x, mu, logvar):\n",
        "    recon_loss = complex_mse_loss(reconstruction, x)\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Add weight decay loss\n",
        "    weight_decay_loss = 0\n",
        "    for param in vae.parameters():\n",
        "        weight_decay_loss += torch.sum(torch.square(param))\n",
        "\n",
        "    return recon_loss + kl_divergence + (weight_decay_loss * vae.weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "def train_vae(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstruction, mu, logvar = model(batch)\n",
        "        loss = criterion(reconstruction, batch, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "def test_vae(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            reconstruction, mu, logvar = model(batch)\n",
        "            loss = criterion(reconstruction, batch, mu, logvar)\n",
        "            test_loss += loss.item()\n",
        "    return test_loss / len(test_loader)\n",
        "\n",
        "\n",
        "# Parameters\n",
        "input_size = 59\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#( input_size, latent_size, neurons, dropout_rate=0.5, weight_decay=0.01)\n",
        "vae = ComplexVAEFFT(input_size, 64,1024,0,0).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(vae.parameters(), lr=0.00001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "tensor_data = torch.tensor(combined_df.values, dtype=torch.float32)\n",
        "train_data, test_data = train_test_split(tensor_data, test_size=0.4,random_state = 42)\n",
        "validation_data, test_data = train_test_split(test_data, test_size=0.5,random_state = 42)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    train_loss = train_vae(vae, train_loader, optimizer, vae_loss, device)\n",
        "    test_loss = test_vae(vae, test_loader, vae_loss, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs},  Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "o5OTM4BaicSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ComplexVAEFFT(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, neurons, dropout_rate=0.5, weight_decay=0.01):\n",
        "        super(ComplexVAEFFT, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "              nn.Linear(input_size * 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons // 4, self.latent_size * 2)\n",
        "          )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "              nn.Linear(self.latent_size, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 4, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons, input_size * 2)\n",
        "          )\n",
        "\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply FFT to input\n",
        "        x_fft = torch.fft.fft(x)\n",
        "\n",
        "        # Separate real and imaginary parts\n",
        "        x_fft_real = x_fft.real\n",
        "        x_fft_imag = x_fft.imag\n",
        "        x_fft_separated = torch.cat((x_fft_real, x_fft_imag), dim=-1)\n",
        "\n",
        "        latent_params = self.encoder(x_fft_separated)\n",
        "        mu = latent_params[:, :self.latent_size]  # Use self.latent_size\n",
        "        logvar = latent_params[:, self.latent_size:]  # Use self.latent_size\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstruction_separated = self.decoder(z)\n",
        "\n",
        "        # Combine real and imaginary parts\n",
        "        reconstruction_real = reconstruction_separated[:, :input_size]\n",
        "        reconstruction_imag = reconstruction_separated[:, input_size:]\n",
        "        reconstruction = torch.complex(reconstruction_real, reconstruction_imag)\n",
        "\n",
        "        # Apply inverse FFT to output\n",
        "        reconstruction_ifft = torch.fft.ifft(reconstruction)\n",
        "\n",
        "        return reconstruction_ifft, mu, logvar\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "def complex_mse_loss(reconstruction, x):\n",
        "    # Compute MSE for real part\n",
        "    reconstruction_real = reconstruction.real\n",
        "    real_loss = nn.functional.mse_loss(reconstruction_real, x, reduction='sum')\n",
        "\n",
        "    # Compute MSE for imaginary part\n",
        "    if torch.is_complex(x):\n",
        "        x_imag = x.imag\n",
        "        reconstruction_imag = reconstruction.imag\n",
        "        imag_loss = nn.functional.mse_loss(reconstruction_imag, x_imag, reduction='sum')\n",
        "    else:\n",
        "        imag_loss = 0\n",
        "\n",
        "    return real_loss + imag_loss\n",
        "\n",
        "\n",
        "def vae_loss(reconstruction, x, mu, logvar):\n",
        "    recon_loss = complex_mse_loss(reconstruction, x)\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Add weight decay loss\n",
        "    weight_decay_loss = 0\n",
        "    for param in vae.parameters():\n",
        "        weight_decay_loss += torch.sum(torch.square(param))\n",
        "\n",
        "    return recon_loss + kl_divergence + (weight_decay_loss * vae.weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "def train_vae(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstruction, mu, logvar = model(batch)\n",
        "        loss = criterion(reconstruction, batch, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "def test_vae(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            reconstruction, mu, logvar = model(batch)\n",
        "            loss = criterion(reconstruction, batch, mu, logvar)\n",
        "            test_loss += loss.item()\n",
        "    return test_loss / len(test_loader)\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create directories in your Google Drive to store the models and logs\n",
        "os.makedirs('/content/gdrive/My Drive/VAE_FFT_5layer', exist_ok=True)\n",
        "os.makedirs('/content/gdrive/My Drive/VAE_FFT_5layer', exist_ok=True)\n",
        "\n",
        "# Define the grid of parameters\n",
        "param_grid = [{'lr': [0.0001, 0.00001],\n",
        "               'weight_decay': [0],\n",
        "               'dropout': [0,0.2,0.4],\n",
        "               'batch_size': [32, 64],\n",
        "               'latent_size': [64, 128],\n",
        "               'neurons': [512,1024]}]\n",
        "\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "# Early stopping parameters\n",
        "input_size = 59\n",
        "epochs = 50\n",
        "n_epochs_stop = 5\n",
        "epochs_no_improve = 5\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tensor_data = torch.tensor(combined_df.values, dtype=torch.float32)\n",
        "train_data, test_data = train_test_split(tensor_data, test_size=0.4,random_state = 42)\n",
        "validation_data, test_data = train_test_split(test_data, test_size=0.5,random_state = 42)\n",
        "\n",
        "# Grid search\n",
        "for params in grid:\n",
        "    best_test_loss = float('inf')\n",
        "    # Instantiate\n",
        "    vae = ComplexVAEFFT(input_size, params['latent_size'],params['neurons'],params['dropout'],params['weight_decay']).to(device)\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=params['lr'])\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_data, batch_size=params['batch_size'], shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "    print(f'with parameters: {params}')\n",
        "\n",
        "    # Train VAE\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_loss = train_vae(vae, train_loader, optimizer, vae_loss, device)\n",
        "        test_loss = test_vae(vae, test_loader, vae_loss, device)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs},  Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if test_loss < best_test_loss:\n",
        "            epochs_no_improve = 0\n",
        "            best_test_loss = test_loss\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "        if epochs_no_improve == n_epochs_stop:\n",
        "            print('Early stopping!')\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Define the paths for saving models and logs\n",
        "    model_path = model_path = f'/content/gdrive/My Drive/VAE_FFT_5layer/{test_loss:.4f}_lr={params[\"lr\"]}_batch={params[\"batch_size\"]}_latent={params[\"latent_size\"]}_neurons={params[\"neurons\"]}_dropout={params[\"dropout\"]}_reg={params[\"weight_decay\"]}.pt'\n",
        "    log_path = f'/content/gdrive/My Drive/VAE_FFT_5layer/{test_loss:.4f}_lr={params[\"lr\"]}_batch={params[\"batch_size\"]}_latent={params[\"latent_size\"]}_neurons={params[\"neurons\"]}_dropout={params[\"dropout\"]}_reg={params[\"weight_decay\"]}_log.csv'\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(vae.state_dict(), model_path)\n",
        "    print(f'Model saved to: {model_path}')\n",
        "\n",
        "    # Save the log\n",
        "    log_df = pd.DataFrame({'parameters': str(params),\n",
        "                           'train_loss': [train_loss],\n",
        "                           'test_loss': [test_loss]})\n",
        "    log_df.to_csv(log_path, index=False)\n",
        "    print(f'Log saved to: {log_path}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "LHu06o2DjAwi",
        "outputId": "ce558883-0b04-4e1c-d096-99988ce2dbd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "with parameters: {'batch_size': 32, 'dropout': 0, 'latent_size': 64, 'lr': 0.0001, 'neurons': 512, 'weight_decay': 0}\n",
            "Epoch 1/50,  Train Loss: 10.9670, Test Loss: 10.7606\n",
            "Epoch 2/50,  Train Loss: 10.5743, Test Loss: 10.7377\n",
            "Epoch 3/50,  Train Loss: 10.5585, Test Loss: 10.7372\n",
            "Epoch 4/50,  Train Loss: 10.5475, Test Loss: 10.7261\n",
            "Epoch 5/50,  Train Loss: 10.5403, Test Loss: 10.7063\n",
            "Epoch 6/50,  Train Loss: 10.5353, Test Loss: 10.7057\n",
            "Epoch 7/50,  Train Loss: 10.5304, Test Loss: 10.7063\n",
            "Epoch 8/50,  Train Loss: 10.5270, Test Loss: 10.7038\n",
            "Epoch 9/50,  Train Loss: 10.5270, Test Loss: 10.6953\n",
            "Epoch 10/50,  Train Loss: 10.5253, Test Loss: 10.7017\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8444d9ad705d>\u001b[0m in \u001b[0;36m<cell line: 190>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m#beta = 0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8444d9ad705d>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}