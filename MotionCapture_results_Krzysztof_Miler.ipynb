{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j2JnbeQELSaV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "VimWly5FLwhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG68XYDXotNw",
        "outputId": "53918ed0-f850-4473-fd11-28bee6ec60bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_from_gdrive(data_dir):\n",
        "  # Initialize an empty list to store the DataFrames\n",
        "  data_frames = []\n",
        "\n",
        "  # Loop through each .csv file in the directory\n",
        "  for dir in data_dir:\n",
        "    for file_name in os.listdir(dir):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(dir, file_name)\n",
        "\n",
        "            # Load the .csv file into a DataFrame\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Remove the first column\n",
        "            df = df.iloc[:, 4:]\n",
        "\n",
        "            df  = df.div(360)\n",
        "\n",
        "            df  = df.clip(upper =1,lower = -1)\n",
        "\n",
        "\n",
        "            # Append the DataFrame to the list\n",
        "            data_frames.append(df)\n",
        "\n",
        "  # Concatenate the DataFrames into a single DataFrame\n",
        "\n",
        "  return data_frames"
      ],
      "metadata": {
        "id": "nqhsDbUtKrWA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the directory path where the .csv files are located in Google Drive\n",
        "\n",
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Normal']\n",
        "\n",
        "combined_df =  load_from_gdrive(data_dir)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(combined_df, test_size=0.4)# 60 40\n"
      ],
      "metadata": {
        "id": "ayevKKFyKzUS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Situations and scenarios/easy']\n",
        "\n",
        "SaS_easy =  load_from_gdrive(data_dir)"
      ],
      "metadata": {
        "id": "fGI1CphdLzCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Physical Activites/easy']\n",
        "\n",
        "PH_AC_easy =  load_from_gdrive(data_dir)"
      ],
      "metadata": {
        "id": "Uwk_2aetL08h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Interaction with enviroment/easy']\n",
        "\n",
        "IwE_easy =  load_from_gdrive(data_dir)\n",
        "\n",
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Interaction with enviroment/hard']\n",
        "\n",
        "IwE_hard =  load_from_gdrive(data_dir)"
      ],
      "metadata": {
        "id": "DL3pQhYeL2ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Locomotion/easy']\n",
        "\n",
        "Loc_easy =  load_from_gdrive(data_dir)\n",
        "\n",
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Locomotion/hard']\n",
        "\n",
        "Loc_hard =  load_from_gdrive(data_dir)\n",
        "\n",
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Locomotion/v hard']\n",
        "\n",
        "Loc_Vhard =  load_from_gdrive(data_dir)"
      ],
      "metadata": {
        "id": "VA3OS0KeL3pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Human Interaction/easy']\n",
        "\n",
        "HI_easy =  load_from_gdrive(data_dir)\n",
        "\n",
        "data_dir = ['/content/drive/MyDrive/28 08 mod/Human Interaction/hard']\n",
        "\n",
        "HI_hard =  load_from_gdrive(data_dir)"
      ],
      "metadata": {
        "id": "-YxFYiulL43a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VAE"
      ],
      "metadata": {
        "id": "qrXaNZr9K1EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_comb = pd.concat(train_data, axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "Dp4XcF5mK34j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class VAEAnomalyTabular(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, dropout_rate=0.4, l1_weight=0.000):\n",
        "        super(VAEAnomalyTabular, self).__init__()\n",
        "        self.encoder = self.make_encoder(input_size, latent_size, dropout_rate)\n",
        "        self.decoder = self.make_decoder(latent_size, input_size, dropout_rate)\n",
        "        self.l1_weight = l1_weight\n",
        "\n",
        "    def make_encoder(self, input_size, latent_size, dropout_rate):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.LeakyReLU(),  # LeakyReLU activation\n",
        "            nn.Dropout(dropout_rate),  # Dropout layer\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(),  # LeakyReLU activation\n",
        "            nn.Dropout(dropout_rate),  # Dropout layer\n",
        "            nn.Linear(256, latent_size * 2)\n",
        "        )\n",
        "\n",
        "    def make_decoder(self, latent_size, output_size, dropout_rate):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(latent_size, 256),\n",
        "            nn.LeakyReLU(),  # LeakyReLU activation\n",
        "            nn.Dropout(dropout_rate),  # Dropout layer\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(),  # LeakyReLU activation\n",
        "            nn.Dropout(dropout_rate),  # Dropout layer\n",
        "            nn.Linear(512, output_size)\n",
        "        )\n",
        "    def reparameterize(self, mu, logvar):\n",
        "          std = torch.exp(0.5 * logvar)\n",
        "          eps = torch.randn_like(std)\n",
        "          return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_params = self.encoder(x)\n",
        "        latent_params = latent_params.view(-1, latent_size * 2)\n",
        "        mu = latent_params[:, :latent_size]\n",
        "        logvar = latent_params[:, latent_size:]\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction, mu, logvar\n",
        "\n",
        "    def train_vae(model, train_loader, optimizer, criterion, device):\n",
        "      model.train()\n",
        "      train_loss = 0\n",
        "      for batch in train_loader:\n",
        "          batch = batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          reconstruction, mu, logvar = model(batch)\n",
        "          loss = criterion(reconstruction, batch, mu, logvar)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item()\n",
        "      return train_loss / len(train_loader)\n",
        "    def vae_loss(reconstruction, x, mu, logvar):\n",
        "      recon_loss = nn.functional.mse_loss(reconstruction, x, reduction='sum')\n",
        "      kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "      return recon_loss + kl_divergence\n",
        "\n",
        "batch_size = 32\n",
        "input_size= 59\n",
        "latent_size= 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "vae = VAEAnomalyTabular(input_size, latent_size)"
      ],
      "metadata": {
        "id": "w1VEp0_LK7Jv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Saved models/vae_model_best1.pth')\n",
        "vae.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "vae.eval().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_yrlb3yK-YW",
        "outputId": "c7f38a69-c2df-4dfa-ac56-46730b6888ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAEAnomalyTabular(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=59, out_features=512, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): Dropout(p=0.4, inplace=False)\n",
              "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): Dropout(p=0.4, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=59, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "batch_size = 1# Since we want to look get the error of 1 sample and not from a batch\n",
        "def calculate_errors(model, data_loader, device):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = batch.to(device)\n",
        "            reconstruction, mu, logvar = model(batch)\n",
        "            recon_error = nn.functional.mse_loss(reconstruction, batch, reduction='sum')\n",
        "            errors.append(recon_error.item())\n",
        "    return errors\n",
        "\n",
        "\n",
        "test_cat = pd.concat(test_data, axis=0, ignore_index=True)\n",
        "tensor_data = torch.tensor(train_data_comb.values, dtype=torch.float32)\n",
        "test_loader = DataLoader(tensor_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Calculate errors on the test dataset\n",
        "test_errors = calculate_errors(vae, test_loader, device)\n",
        "\n",
        "test_errors = np.array(test_errors)\n",
        "\n",
        "\n",
        "quantile_threshold_99 = np.percentile(test_errors, 99)\n",
        "quantile_threshold_95 = np.percentile(test_errors, 95)\n",
        "quantile_threshold_90 = np.percentile(test_errors, 90)\n",
        "quantile_threshold_85 = np.percentile(test_errors, 85)\n",
        "\n",
        "quantile_threshold_50 = np.percentile(test_errors, 50)\n",
        "\n",
        "print(f\"Quantile Threshold: {quantile_threshold_99:.4f} Quantile Threshold: {quantile_threshold_95:.4f} \\\n",
        "Quantile Threshold: {quantile_threshold_90:.4f} Quantile Threshold: {quantile_threshold_85:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6njV-n2LHgz",
        "outputId": "c53653c6-3697-4204-9bdb-cd329b7187b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile Threshold: 2.3933 Quantile Threshold: 1.8938 Quantile Threshold: 0.9103 Quantile Threshold: 0.8233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "flattened_errors = test_errors\n",
        "# Sample reconstruction errors\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.histplot(flattened_errors, bins=30, kde=False)\n",
        "\n",
        "\n",
        "percentiles = np.percentile(flattened_errors, [85, 90, 95, 99])\n",
        "\n",
        "plt.axvline(np.percentile(flattened_errors,99), color='green', linestyle='--', label=f'{int(99)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,95), color='orange', linestyle='--', label=f'{int(95)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,90), color='violet', linestyle='--', label=f'{int(90)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,85), color='teal', linestyle='--', label=f'{int(85)}th Percentile')\n",
        "\n",
        "\n",
        "# Add a vertical line for the median\n",
        "median = np.median(flattened_errors)\n",
        "plt.axvline(median, color='red', linestyle='dashdot', label=f'Median')\n",
        "\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Reconstruction Errors', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.savefig(f'/content/drive/MyDrive/VAE_HEATMAPS/thresholds.png')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "8yjG30hwLLU5",
        "outputId": "81bbd101-c41f-4c83-c0fa-7183f6faf3b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1bc287c0c5e0>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Sample reconstruction errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate the percentiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'flattened_errors' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_err_list_from_dataset__vae(dataset):\n",
        "  error_list=[]\n",
        "  for record in dataset:\n",
        "\n",
        "    tensor_data = torch.tensor(record.values, dtype=torch.float32)#zmieniaÄ‡\n",
        "    test_loader = DataLoader(tensor_data, batch_size=batch_size, shuffle=False)\n",
        "    all_errors = calculate_errors(vae, test_loader, device)\n",
        "    error_list.append(all_errors)\n",
        "\n",
        "  return error_list\n"
      ],
      "metadata": {
        "id": "iRi2byT6LfWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_against_thresh_pred(error_list,threshold,precent=0.05):#\n",
        "  predictions=[]\n",
        "  for item in error_list:\n",
        "    anomaly = 0\n",
        "    normal=0\n",
        "    for sample in item:\n",
        "        #print(sample)\n",
        "        if sample > threshold:\n",
        "            anomaly = anomaly+1\n",
        "        else:\n",
        "            normal = normal+1\n",
        "    if anomaly > len(error_list)*precent:\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "_m-skF4PLosg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "err_SaS_easy =create_err_list_from_dataset__vae(SaS_easy)#~12 min\n",
        "err_PH_AC_easy =create_err_list_from_dataset__vae(PH_AC_easy)#\n",
        "err_IwE_easy =create_err_list_from_dataset__vae(IwE_easy)\n",
        "err_IwE_hard =create_err_list_from_dataset__vae(IwE_hard)# 15 min\n",
        "err_Loc_easy =create_err_list_from_dataset__vae(Loc_easy)\n",
        "err_Loc_hard =create_err_list_from_dataset__vae(Loc_hard)#16 min\n",
        "err_Loc_Vhard =create_err_list_from_dataset__vae(Loc_Vhard)#16 30\n",
        "err_HI_easy =create_err_list_from_dataset__vae(HI_easy)\n",
        "err_HI_hard =create_err_list_from_dataset__vae(HI_hard)#20 min\n",
        "\n",
        "error_dict = {\n",
        "    'err_SaS_easy': err_SaS_easy,\n",
        "    'err_PH_AC_easy': err_PH_AC_easy,\n",
        "    'err_IwE_easy': err_IwE_easy,\n",
        "    'err_IwE_hard': err_IwE_hard,\n",
        "    'err_Loc_easy': err_Loc_easy,\n",
        "    'err_Loc_hard': err_Loc_hard,\n",
        "    'err_Loc_Vhard': err_Loc_Vhard,\n",
        "    'err_HI_easy': err_HI_easy,\n",
        "    'err_HI_hard': err_HI_hard\n",
        "}\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/VAE_HEATMAPS/error_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(error_dict, file)\n"
      ],
      "metadata": {
        "id": "-SFOBuBCLqvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err_NORMAL= create_err_list_from_dataset__vae(test_data)\n",
        "\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/VAE_HEATMAPS/norm_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(err_NORMAL, file)"
      ],
      "metadata": {
        "id": "QEKPqlSHLsj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the error_dict object from the file\n",
        "with open('/content/drive/MyDrive/VAE_HEATMAPS/error_dict.pkl', 'rb') as file:\n",
        "    loaded_error_dict = pickle.load(file)\n",
        "\n",
        "# Access the loaded objects\n",
        "err_SaS_easy = loaded_error_dict['err_SaS_easy']\n",
        "err_PH_AC_easy = loaded_error_dict['err_PH_AC_easy']\n",
        "err_IwE_easy = loaded_error_dict['err_IwE_easy']\n",
        "err_IwE_hard = loaded_error_dict['err_IwE_hard']\n",
        "err_Loc_easy = loaded_error_dict['err_Loc_easy']\n",
        "err_Loc_hard = loaded_error_dict['err_Loc_hard']\n",
        "err_Loc_Vhard = loaded_error_dict['err_Loc_Vhard']\n",
        "err_HI_easy = loaded_error_dict['err_HI_easy']\n",
        "err_HI_hard = loaded_error_dict['err_HI_hard']\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/VAE_HEATMAPS/norm_dict.pkl', 'rb') as file:\n",
        "    normal = pickle.load(file)\n",
        "\n",
        "err_NORMAL = normal"
      ],
      "metadata": {
        "id": "wpBzI1PKLtBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VAE CNN"
      ],
      "metadata": {
        "id": "j2JnbeQELSaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_comb = pd.concat(train_data, axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "quIBDTkXLT6y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class VAEAnomalyConv(nn.Module):\n",
        "    def __init__(self, input_channels, latent_size, sequence_length=59,  dropout_rate=0.0, l1_weight=0.000):\n",
        "        super(VAEAnomalyConv, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.l1_weight = l1_weight\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Flatten(start_dim=1, end_dim=-1),\n",
        "            nn.Linear(in_features=1888, out_features=latent_size)\n",
        "        )\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(in_features=latent_size, out_features=32*sequence_length),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Unflatten(1, (32, sequence_length)),\n",
        "            nn.ConvTranspose1d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      mu, logvar = self.encode(x)\n",
        "      #print(\"Shape after Flatten layer in encoder:\", mu.shape)\n",
        "      z = self.reparameterize(mu, logvar)\n",
        "      reconstruction = self.decode(z)\n",
        "      return reconstruction, mu, logvar\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "      for i, layer in enumerate(self.encoder):\n",
        "          x = layer(x)\n",
        "          #print(f\"Shape after layer {i} in encoder:\", x.shape)\n",
        "      mu = x\n",
        "      logvar = x\n",
        "      return mu, logvar\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, z):\n",
        "        decoded = self.decoder(z)\n",
        "        return decoded\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def l1_regularization(self):\n",
        "        l1_reg = torch.tensor(0.0)\n",
        "        for param in self.parameters():\n",
        "            l1_reg += torch.norm(param, 1)\n",
        "        return self.l1_weight * l1_reg\n",
        "\n",
        "# Define the loss function\n",
        "def vae_loss(reconstruction, x, mu, logvar):\n",
        "    recon_loss = nn.functional.mse_loss(reconstruction, x, reduction='sum')\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_divergence\n",
        "\n",
        "batch_size = 32\n",
        "input_size= 59\n",
        "latent_size= 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "vae = VAEAnomalyConv(input_size, latent_size)"
      ],
      "metadata": {
        "id": "F-zF0SvGMBuY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Saved models/cnn_vae_model_best1.pth')\n",
        "vae.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "vae.eval().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-GbDInrMEot",
        "outputId": "af376e2b-f30e-48da-dc18-68a89f2c8ca2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAEAnomalyConv(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Dropout(p=0.0, inplace=False)\n",
              "    (3): Flatten(start_dim=1, end_dim=-1)\n",
              "    (4): Linear(in_features=1888, out_features=64, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=1888, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Dropout(p=0.0, inplace=False)\n",
              "    (3): Unflatten(dim=1, unflattened_size=(32, 59))\n",
              "    (4): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "def test_vae(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    reconstruction_errors = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            batch = batch.view(batch.shape[0], 1, batch.shape[1])\n",
        "            reconstruction, mu, logvar = model(batch)\n",
        "            loss = criterion(reconstruction, batch, mu, logvar)\n",
        "            test_loss += loss.item()\n",
        "            reconstruction_errors.extend(loss.item() for _ in range(batch.size(0)))\n",
        "    return test_loss / len(test_loader), reconstruction_errors\n",
        "\n",
        "test_data_comb = pd.concat(test_data, axis=0, ignore_index=True)\n",
        "tens_test_data = torch.tensor(test_data_comb.values, dtype=torch.float32)\n",
        "test_loader = DataLoader(tens_test_data.unsqueeze(2), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "mean_test_loss, reconstruction_errors = test_vae(vae, test_loader, vae_loss, device)\n",
        "\n",
        "# Convert errors to a numpy array\n",
        "test_errors = np.array(reconstruction_errors)\n",
        "\n",
        "# Define the quantile threshold\n",
        "quantile_threshold_99 = np.percentile(test_errors, 99)\n",
        "quantile_threshold_95 = np.percentile(test_errors, 95)\n",
        "quantile_threshold_90 = np.percentile(test_errors, 90)\n",
        "quantile_threshold_85 = np.percentile(test_errors, 85)\n",
        "\n",
        "quantile_threshold_50 = np.percentile(test_errors, 50)\n",
        "\n",
        "print(f\"Quantile Threshold: {quantile_threshold_99:.4f} Quantile Threshold: {quantile_threshold_95:.4f} \\\n",
        "Quantile Threshold: {quantile_threshold_90:.4f} Quantile Threshold: {quantile_threshold_85:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dyZSlwijMJ9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "flattened_errors = test_errors\n",
        "# Sample reconstruction errors\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.histplot(flattened_errors, bins=30, kde=False)\n",
        "\n",
        "# Calculate the percentiles\n",
        "percentiles = np.percentile(flattened_errors, [85, 90, 95, 99])\n",
        "\n",
        "plt.axvline(np.percentile(flattened_errors,99), color='green', linestyle='--', label=f'{int(99)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,95), color='orange', linestyle='--', label=f'{int(95)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,90), color='violet', linestyle='--', label=f'{int(90)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,85), color='teal', linestyle='--', label=f'{int(85)}th Percentile')\n",
        "\n",
        "\n",
        "# Calculate and add a vertical line for the median\n",
        "median = np.median(flattened_errors)\n",
        "plt.axvline(median, color='red', linestyle='dashdot', label=f'Median')\n",
        "\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Reconstruction Errors', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.savefig(f'/content/drive/MyDrive/CNN_VAE_HEATMAPS/thresholds.png')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y7HAbOUSPFlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_err_list_from_dataset__cnn_vae(dataset):\n",
        "  error_list=[]\n",
        "  for record in dataset:\n",
        "\n",
        "    tensor_data = torch.tensor(record.values, dtype=torch.float32)\n",
        "    test_loader = DataLoader(tensor_data, batch_size=batch_size, shuffle=False)\n",
        "    _, all_errors = test_vae(vae, test_loader, vae_loss, device)\n",
        "    error_list.append(all_errors)\n",
        "\n",
        "  return error_list"
      ],
      "metadata": {
        "id": "BQztx-H-MOFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "err_SaS_easy =create_err_list_from_dataset__cnn_vae(SaS_easy)\n",
        "err_PH_AC_easy =create_err_list_from_dataset__cnn_vae(PH_AC_easy)#14 min\n",
        "err_IwE_easy =create_err_list_from_dataset__cnn_vae(IwE_easy)#16 min\n",
        "err_IwE_hard =create_err_list_from_dataset__cnn_vae(IwE_hard)\n",
        "err_Loc_easy =create_err_list_from_dataset__cnn_vae(Loc_easy)\n",
        "err_Loc_hard =create_err_list_from_dataset__cnn_vae(Loc_hard)\n",
        "err_Loc_Vhard =create_err_list_from_dataset__cnn_vae(Loc_Vhard)#21 min\n",
        "err_HI_easy =create_err_list_from_dataset__cnn_vae(HI_easy)\n",
        "err_HI_hard =create_err_list_from_dataset__cnn_vae(HI_hard)# 25 min\n",
        "\n",
        "error_dict = {\n",
        "    'err_SaS_easy': err_SaS_easy,\n",
        "    'err_PH_AC_easy': err_PH_AC_easy,\n",
        "    'err_IwE_easy': err_IwE_easy,\n",
        "    'err_IwE_hard': err_IwE_hard,\n",
        "    'err_Loc_easy': err_Loc_easy,\n",
        "    'err_Loc_hard': err_Loc_hard,\n",
        "    'err_Loc_Vhard': err_Loc_Vhard,\n",
        "    'err_HI_easy': err_HI_easy,\n",
        "    'err_HI_hard': err_HI_hard\n",
        "}\n",
        "\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/CNN_VAE_HEATMAPS/error_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(error_dict, file)"
      ],
      "metadata": {
        "id": "5xYa-VL9MV1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err_NORMAL= create_err_list_from_dataset__cnn_vae(test_data)\n",
        "\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/CNN_VAE_HEATMAPS/norm_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(err_NORMAL, file)"
      ],
      "metadata": {
        "id": "mZMIWAfXMXPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the error_dict object from the file\n",
        "with open('/content/drive/MyDrive/CNN_VAE_HEATMAPS/error_dict.pkl', 'rb') as file:\n",
        "    loaded_error_dict = pickle.load(file)\n",
        "\n",
        "# Access the loaded objects\n",
        "err_SaS_easy = loaded_error_dict['err_SaS_easy']\n",
        "err_PH_AC_easy = loaded_error_dict['err_PH_AC_easy']\n",
        "err_IwE_easy = loaded_error_dict['err_IwE_easy']\n",
        "err_IwE_hard = loaded_error_dict['err_IwE_hard']\n",
        "err_Loc_easy = loaded_error_dict['err_Loc_easy']\n",
        "err_Loc_hard = loaded_error_dict['err_Loc_hard']\n",
        "err_Loc_Vhard = loaded_error_dict['err_Loc_Vhard']\n",
        "err_HI_easy = loaded_error_dict['err_HI_easy']\n",
        "err_HI_hard = loaded_error_dict['err_HI_hard']\n"
      ],
      "metadata": {
        "id": "vnbKGkhAMXrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/CNN_VAE_HEATMAPS/norm_dict.pkl', 'rb') as file:\n",
        "    normal = pickle.load(file)\n",
        "\n",
        "err_NORMAL = normal"
      ],
      "metadata": {
        "id": "OVeIEdsiMZFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FFT VAE"
      ],
      "metadata": {
        "id": "O41KrX23McKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_comb = pd.concat(train_data, axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "y70LBdG7Md37"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ComplexVAEFFT(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, neurons, dropout_rate=0.5, weight_decay=0.01):\n",
        "        super(ComplexVAEFFT, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "              nn.Linear(input_size * 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons // 4, self.latent_size * 2)\n",
        "          )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "              nn.Linear(self.latent_size, neurons // 4),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 4, neurons // 2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(dropout_rate),\n",
        "              nn.Linear(neurons // 2, neurons),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(neurons, input_size * 2)\n",
        "          )\n",
        "\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply FFT to input\n",
        "        x_fft = torch.fft.fft(x)\n",
        "\n",
        "        # Separate real and imaginary parts\n",
        "        x_fft_real = x_fft.real\n",
        "        x_fft_imag = x_fft.imag\n",
        "        x_fft_separated = torch.cat((x_fft_real, x_fft_imag), dim=-1)\n",
        "\n",
        "        latent_params = self.encoder(x_fft_separated)\n",
        "        mu = latent_params[:, :self.latent_size]  # Use self.latent_size\n",
        "        logvar = latent_params[:, self.latent_size:]  # Use self.latent_size\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstruction_separated = self.decoder(z)\n",
        "\n",
        "        # Combine real and imaginary parts\n",
        "        reconstruction_real = reconstruction_separated[:, :input_size]\n",
        "        reconstruction_imag = reconstruction_separated[:, input_size:]\n",
        "        reconstruction = torch.complex(reconstruction_real, reconstruction_imag)\n",
        "\n",
        "        # Apply inverse FFT to output\n",
        "        reconstruction_ifft = torch.fft.ifft(reconstruction)\n",
        "\n",
        "        return reconstruction_ifft, mu, logvar\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "def complex_mse_loss(reconstruction, x):\n",
        "    # Compute MSE for real part\n",
        "    reconstruction_real = reconstruction.real\n",
        "    real_loss = nn.functional.mse_loss(reconstruction_real, x, reduction='sum')\n",
        "\n",
        "    # Compute MSE for imaginary part\n",
        "    if torch.is_complex(x):\n",
        "        x_imag = x.imag\n",
        "        reconstruction_imag = reconstruction.imag\n",
        "        imag_loss = nn.functional.mse_loss(reconstruction_imag, x_imag, reduction='sum')\n",
        "    else:\n",
        "        imag_loss = 0\n",
        "\n",
        "    return real_loss + imag_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def vae_loss(reconstruction, x, mu, logvar):\n",
        "    recon_loss = complex_mse_loss(reconstruction, x)\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Add weight decay loss\n",
        "    weight_decay_loss = 0\n",
        "    for param in vae.parameters():\n",
        "        weight_decay_loss += torch.sum(torch.square(param))\n",
        "\n",
        "    return recon_loss + kl_divergence + (weight_decay_loss * vae.weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "def train_vae(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstruction, mu, logvar = model(batch)\n",
        "        loss = criterion(reconstruction, batch, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "def test_vae(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            reconstruction, mu, logvar = model(batch)\n",
        "            loss = criterion(reconstruction, batch, mu, logvar)\n",
        "            test_loss += loss.item()\n",
        "    return test_loss / len(test_loader)\n",
        "\n",
        "\n",
        "# Early stopping parameters\n",
        "input_size = 59\n",
        "epochs = 10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#(self, input_size, latent_size, neurons, dropout_rate=0.5, weight_decay=0.01)\n",
        "vae = ComplexVAEFFT(input_size, 64,1024,0,0).to(device)\n"
      ],
      "metadata": {
        "id": "6NhcXOSzMi3L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Saved models/fft_vae_model_best1.pt', map_location=torch.device('cpu'))\n",
        "vae.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "vae.eval().to(device)"
      ],
      "metadata": {
        "id": "lul1SjcLMlT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reconstruction_error_fft_vae(model, data_loader):\n",
        "    model.eval()\n",
        "    reconstruction_errors = []\n",
        "    for batch in data_loader:\n",
        "        x = batch.to(device)\n",
        "        reconstruction, mu, logvar = model(x)\n",
        "        recon_error = vae_loss(reconstruction, x, mu, logvar).item()  # Use vae_loss function\n",
        "        reconstruction_errors.append(recon_error)\n",
        "    return reconstruction_errors"
      ],
      "metadata": {
        "id": "LX-OgDBIMr8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_err_list_from_dataset__fft_vae(dataset):\n",
        "    error_list = []\n",
        "    for record in dataset:\n",
        "        # Convert the record DataFrame into a tensor\n",
        "\n",
        "        #train_data_comb = pd.concat(train_data, axis=0, ignore_index=True)\n",
        "        tensor_train_data = torch.tensor(record.values, dtype=torch.float32)\n",
        "        train_loader = DataLoader(tensor_train_data, batch_size=1, shuffle=False)\n",
        "        #record_tensor = torch.Tensor(record.values)\n",
        "\n",
        "        # Calculate the reconstruction error for the record\n",
        "        reconstruction_error = calculate_reconstruction_error_fft_vae(vae, train_loader)\n",
        "\n",
        "        error_list.append(reconstruction_error)\n",
        "\n",
        "    return error_list"
      ],
      "metadata": {
        "id": "W91rMIPWMtVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_errors = create_err_list_from_dataset__fft_vae(test_data)\n",
        "\n",
        "import numpy as np\n",
        "flattened_errors = [error for sublist in test_errors for error in sublist]\n",
        "\n",
        "quantile_threshold_99 = np.percentile(flattened_errors, 99)\n",
        "quantile_threshold_95 = np.percentile(flattened_errors, 95)\n",
        "quantile_threshold_90 = np.percentile(flattened_errors, 90)\n",
        "quantile_threshold_85 = np.percentile(flattened_errors, 85)\n",
        "\n",
        "quantile_threshold_50 = np.percentile(flattened_errors, 50)\n",
        "\n",
        "print(f\"Quantile Threshold: {quantile_threshold_99:.4f} Quantile Threshold: {quantile_threshold_95:.4f} \\\n",
        "Quantile Threshold: {quantile_threshold_90:.4f} Quantile Threshold: {quantile_threshold_85:.4f}\")"
      ],
      "metadata": {
        "id": "FKy_1Z4rMvvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "flattened_errors = test_errors\n",
        "# Sample reconstruction errors\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.histplot(flattened_errors, bins=30, kde=False)\n",
        "\n",
        "percentiles = np.percentile(flattened_errors, [85, 90, 95, 99])\n",
        "\n",
        "plt.axvline(np.percentile(flattened_errors,99), color='green', linestyle='--', label=f'{int(99)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,95), color='orange', linestyle='--', label=f'{int(95)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,90), color='violet', linestyle='--', label=f'{int(90)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,85), color='teal', linestyle='--', label=f'{int(85)}th Percentile')\n",
        "\n",
        "\n",
        "# Add a vertical line for the median\n",
        "median = np.median(flattened_errors)\n",
        "plt.axvline(median, color='red', linestyle='dashdot', label=f'Median')\n",
        "\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Reconstruction Errors', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.savefig(f'/content/drive/MyDrive/CNN_VAE_HEATMAPS/thresholds.png')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1oN_piY2PU7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "err_SaS_easy =create_err_list_from_dataset__fft_vae(SaS_easy)\n",
        "err_PH_AC_easy =create_err_list_from_dataset__fft_vae(PH_AC_easy)\n",
        "err_IwE_easy =create_err_list_from_dataset__fft_vae(IwE_easy)\n",
        "err_IwE_hard =create_err_list_from_dataset__fft_vae(IwE_hard)\n",
        "err_Loc_easy =create_err_list_from_dataset__fft_vae(Loc_easy)\n",
        "err_Loc_hard =create_err_list_from_dataset__fft_vae(Loc_hard)\n",
        "err_Loc_Vhard =create_err_list_from_dataset__fft_vae(Loc_Vhard)\n",
        "err_HI_easy =create_err_list_from_dataset__fft_vae(HI_easy)\n",
        "err_HI_hard =create_err_list_from_dataset__fft_vae(HI_hard)#29 min\n",
        "\n",
        "error_dict = {\n",
        "    'err_SaS_easy': err_SaS_easy,\n",
        "    'err_PH_AC_easy': err_PH_AC_easy,\n",
        "    'err_IwE_easy': err_IwE_easy,\n",
        "    'err_IwE_hard': err_IwE_hard,\n",
        "    'err_Loc_easy': err_Loc_easy,\n",
        "    'err_Loc_hard': err_Loc_hard,\n",
        "    'err_Loc_Vhard': err_Loc_Vhard,\n",
        "    'err_HI_easy': err_HI_easy,\n",
        "    'err_HI_hard': err_HI_hard\n",
        "}\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/FFT_C_VAE_HEATMAPS/error_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(error_dict, file)\n",
        "\n"
      ],
      "metadata": {
        "id": "_xGdIW0pMysO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err_NORMAL= create_err_list_from_dataset__fft_vae(test_data)\n",
        "\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/FFT_C_VAE_HEATMAPS/norm_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(err_NORMAL, file)"
      ],
      "metadata": {
        "id": "XVkLGgLXM0HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the error_dict object from the file\n",
        "with open('/content/drive/MyDrive/FFT_C_VAE_HEATMAPS/error_dict.pkl', 'rb') as file:\n",
        "    loaded_error_dict = pickle.load(file)\n",
        "\n",
        "# Access the loaded objects\n",
        "err_SaS_easy = loaded_error_dict['err_SaS_easy']\n",
        "err_PH_AC_easy = loaded_error_dict['err_PH_AC_easy']\n",
        "err_IwE_easy = loaded_error_dict['err_IwE_easy']\n",
        "err_IwE_hard = loaded_error_dict['err_IwE_hard']\n",
        "err_Loc_easy = loaded_error_dict['err_Loc_easy']\n",
        "err_Loc_hard = loaded_error_dict['err_Loc_hard']\n",
        "err_Loc_Vhard = loaded_error_dict['err_Loc_Vhard']\n",
        "err_HI_easy = loaded_error_dict['err_HI_easy']\n",
        "err_HI_hard = loaded_error_dict['err_HI_hard']"
      ],
      "metadata": {
        "id": "xJx1oU5hM1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/FFT_C_VAE_HEATMAPS/norm_dict.pkl', 'rb') as file:\n",
        "    normal = pickle.load(file)\n",
        "\n",
        "err_NORMAL = normal"
      ],
      "metadata": {
        "id": "f-lfa17pM2hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM VAE"
      ],
      "metadata": {
        "id": "coKgSZ6uM4MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(combined_df, test_size=0.4)# 60 40\n"
      ],
      "metadata": {
        "id": "DV0OTmOoM7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "class VAE_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size,dropout_rate):\n",
        "        super(VAE_LSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.latent_size = latent_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True,dropout = dropout_rate)\n",
        "        self.fc_mu = nn.Linear(hidden_size, latent_size)\n",
        "        self.fc_log_var = nn.Linear(hidden_size, latent_size)\n",
        "        self.decoder = nn.LSTM(latent_size, hidden_size, batch_first=True,dropout = dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def encode(self, x):\n",
        "        _, (h_n, _) = self.encoder(x)\n",
        "        h_n = h_n.squeeze()\n",
        "        mu = self.fc_mu(h_n)\n",
        "        log_var = self.fc_log_var(h_n)\n",
        "        return mu, log_var\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = z.unsqueeze(0)\n",
        "        h, _ = self.decoder(z)\n",
        "        x_recon = self.fc(h.squeeze(0))\n",
        "        return x_recon\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mu, log_var\n",
        "\n",
        "\n",
        "input_size = 59  # Number of features in a data frame\n",
        "hidden_size = 256   # Set hidden size\n",
        "latent_size = 64  # Set latent size\n",
        "timestep = 50  # Set timestep size\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = VAE_LSTM(input_size, hidden_size, latent_size,dropout_rate = 0.2)"
      ],
      "metadata": {
        "id": "UYkGW77nM--4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained weights\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Saved models/lstm50_vae_model_best1.pth', map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval().to(device)"
      ],
      "metadata": {
        "id": "BXB1SUpeNDax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reconstruction_error(model, data_loader):\n",
        "    model.eval()\n",
        "    reconstruction_errors = []\n",
        "    for batch in data_loader:\n",
        "        x = batch.to(device)\n",
        "        x_recon, _, _ = model(x)\n",
        "        recon_error = nn.MSELoss(reduction='none')(x_recon, x).sum(dim=1).mean().item()\n",
        "        reconstruction_errors.append(recon_error)\n",
        "    return reconstruction_errors\n"
      ],
      "metadata": {
        "id": "95YzGG2ANG60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_err_list_from_dataset__lstm_vae(dataset, window_size, window_slide):\n",
        "    error_list = []\n",
        "    for record in dataset:\n",
        "        record_error_list = []\n",
        "        # Iterate over the record with a sliding window\n",
        "        for i in range(0, len(record), window_slide):\n",
        "            end = i + window_size\n",
        "\n",
        "            # If the end of the window exceeds the length of the record\n",
        "            if end > len(record):\n",
        "                # Adjust the end to be the end of the record\n",
        "                end = len(record)\n",
        "\n",
        "            # Get the window from the record\n",
        "            window = record[i:end]\n",
        "\n",
        "            # Convert the window DataFrame into a tensor\n",
        "            sequence_tensor = torch.Tensor(window.values)\n",
        "\n",
        "            # Create a DataLoader for the window\n",
        "            data_loader = DataLoader([sequence_tensor], batch_size=1)\n",
        "\n",
        "            # Calculate the reconstruction error for the window\n",
        "            reconstruction_error = calculate_reconstruction_error(model, data_loader)\n",
        "\n",
        "            # Extract the number\n",
        "            if isinstance(reconstruction_error, (list, torch.Tensor)):\n",
        "                reconstruction_error = reconstruction_error[0]\n",
        "\n",
        "            record_error_list.append(reconstruction_error)\n",
        "\n",
        "        error_list.append(record_error_list)\n",
        "\n",
        "    return error_list\n"
      ],
      "metadata": {
        "id": "QVZIyeQaNPSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = create_err_list_from_dataset__lstm_vae(test_data, window_size=10, window_slide=5)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "flattened_errors = [error for sublist in errors for error in sublist]\n",
        "\n",
        "quantile_threshold_99 = np.percentile(flattened_errors, 99)\n",
        "quantile_threshold_95 = np.percentile(flattened_errors, 95)\n",
        "quantile_threshold_90 = np.percentile(flattened_errors, 90)\n",
        "quantile_threshold_85 = np.percentile(flattened_errors, 85)\n",
        "\n",
        "quantile_threshold_50 = np.percentile(flattened_errors, 50)\n",
        "\n",
        "print(f\"Quantile Threshold: {quantile_threshold_99:.4f} Quantile Threshold: {quantile_threshold_95:.4f} \\\n",
        "Quantile Threshold: {quantile_threshold_90:.4f} Quantile Threshold: {quantile_threshold_85:.4f}\")"
      ],
      "metadata": {
        "id": "WcPInD7XNS21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Sample reconstruction errors\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.histplot(flattened_errors, bins=30, kde=False)\n",
        "\n",
        "# Calculate the percentiles\n",
        "percentiles = np.percentile(flattened_errors, [85, 90, 95, 99])\n",
        "\n",
        "plt.axvline(np.percentile(flattened_errors,99), color='green', linestyle='--', label=f'{int(99)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,95), color='orange', linestyle='--', label=f'{int(95)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,90), color='violet', linestyle='--', label=f'{int(90)}th Percentile')\n",
        "plt.axvline(np.percentile(flattened_errors,85), color='teal', linestyle='--', label=f'{int(85)}th Percentile')\n",
        "\n",
        "\n",
        "# Add a vertical line for the median\n",
        "median = np.median(flattened_errors)\n",
        "plt.axvline(median, color='red', linestyle='dashdot', label=f'Median')\n",
        "\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Reconstruction Errors', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.savefig(f'/content/drive/MyDrive/LSTM_VAE_HEATMAPS/thresholds.png')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SeMeMo7-Pa5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "win_s = 50\n",
        "\n",
        "err_SaS_easy =create_err_list_from_dataset__lstm_vae(SaS_easy, window_size=win_s, window_slide=5)#~12 min\n",
        "err_PH_AC_easy =create_err_list_from_dataset__lstm_vae(PH_AC_easy, window_size=win_s, window_slide=5)#\n",
        "err_IwE_easy =create_err_list_from_dataset__lstm_vae(IwE_easy, window_size=win_s, window_slide=5)\n",
        "err_IwE_hard =create_err_list_from_dataset__lstm_vae(IwE_hard, window_size=win_s, window_slide=5)# 15 min tutaj\n",
        "err_Loc_easy =create_err_list_from_dataset__lstm_vae(Loc_easy, window_size=win_s, window_slide=5)\n",
        "err_Loc_hard =create_err_list_from_dataset__lstm_vae(Loc_hard, window_size=win_s, window_slide=5)#16 min\n",
        "err_Loc_Vhard =create_err_list_from_dataset__lstm_vae(Loc_Vhard, window_size=win_s, window_slide=5)#16 30\n",
        "err_HI_easy =create_err_list_from_dataset__lstm_vae(HI_easy, window_size=win_s, window_slide=5)\n",
        "err_HI_hard =create_err_list_from_dataset__lstm_vae(HI_hard, window_size=win_s, window_slide=5)#20 min\n",
        "\n",
        "error_dict = {\n",
        "    'err_SaS_easy': err_SaS_easy,\n",
        "    'err_PH_AC_easy': err_PH_AC_easy,\n",
        "    'err_IwE_easy': err_IwE_easy,\n",
        "    'err_IwE_hard': err_IwE_hard,\n",
        "    'err_Loc_easy': err_Loc_easy,\n",
        "    'err_Loc_hard': err_Loc_hard,\n",
        "    'err_Loc_Vhard': err_Loc_Vhard,\n",
        "    'err_HI_easy': err_HI_easy,\n",
        "    'err_HI_hard': err_HI_hard\n",
        "}\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/LSTM_50_VAE_HEATMAPS/error_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(error_dict, file)\n",
        "\n",
        "err_NORMAL= create_err_list_from_dataset__lstm_vae(test_data, window_size=win_s, window_slide=5)\n",
        "\n",
        "# Save the error_dict object to a file\n",
        "with open('/content/drive/MyDrive/LSTM_50_VAE_HEATMAPS/norm_dict.pkl', 'wb') as file:\n",
        "    pickle.dump(err_NORMAL, file)"
      ],
      "metadata": {
        "id": "Nk1y_ZPINVj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the error_dict object from the file\n",
        "with open('/content/drive/MyDrive/LSTM_50_VAE_HEATMAPS/error_dict.pkl', 'rb') as file:\n",
        "    loaded_error_dict = pickle.load(file)\n",
        "\n",
        "# Access the loaded objects\n",
        "err_SaS_easy = loaded_error_dict['err_SaS_easy']\n",
        "err_PH_AC_easy = loaded_error_dict['err_PH_AC_easy']\n",
        "err_IwE_easy = loaded_error_dict['err_IwE_easy']\n",
        "err_IwE_hard = loaded_error_dict['err_IwE_hard']\n",
        "err_Loc_easy = loaded_error_dict['err_Loc_easy']\n",
        "err_Loc_hard = loaded_error_dict['err_Loc_hard']\n",
        "err_Loc_Vhard = loaded_error_dict['err_Loc_Vhard']\n",
        "err_HI_easy = loaded_error_dict['err_HI_easy']\n",
        "err_HI_hard = loaded_error_dict['err_HI_hard']\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/LSTM_50_VAE_HEATMAPS/norm_dict.pkl', 'rb') as file:\n",
        "    normal = pickle.load(file)"
      ],
      "metadata": {
        "id": "4Str0rDYNWP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final results (Shared)"
      ],
      "metadata": {
        "id": "zHc4-_rkNYTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, average_precision_score\n",
        "\n",
        "def multiple_random_sampling(err_NORMAL,err_LIST,threshold,limit = 100,precent=0.05):\n",
        "\n",
        "  avg_auc =[]\n",
        "  avg_f1 = []\n",
        "  avg_prec=[]\n",
        "  avg_rec=[]\n",
        "  avg_AP=[]\n",
        "\n",
        "  for N in range(limit):\n",
        "    normal_errors = err_NORMAL\n",
        "    anomaly_errors =  err_LIST#err_LIST#err_IwE_easy#err_SaS_easy#err_PH_AC_easy#err_IwE_easy\n",
        "\n",
        "    normal_errors = np.array(normal_errors,dtype=object)\n",
        "    anomaly_errors = np.array(anomaly_errors,dtype=object)\n",
        "\n",
        "    # Create labels\n",
        "    normal_labels = np.zeros(len(normal_errors)) # normal is '0'\n",
        "    anomaly_labels = np.ones(len(anomaly_errors)) # anomaly is '1'\n",
        "\n",
        "    # Combine errors and labels\n",
        "    errors = np.concatenate((normal_errors, anomaly_errors))\n",
        "    labels = np.concatenate((normal_labels, anomaly_labels))\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame({'errors': errors, 'labels': labels})\n",
        "\n",
        "    # Apply random undersampling\n",
        "    undersample = RandomUnderSampler(sampling_strategy='majority') # 'majority' will undersample the majority class\n",
        "    X_res, y_res = undersample.fit_resample(df[['errors']], df['labels'])\n",
        "\n",
        "    X_res_list = X_res.values.tolist()\n",
        "    X_res_flat = [item for sublist in X_res_list for item in sublist]\n",
        "\n",
        "    predictions = check_against_thresh_pred(X_res_flat, threshold,precent)\n",
        "\n",
        "    auc_score = roc_auc_score(y_res, predictions)\n",
        "    f1 = f1_score(y_res, predictions)\n",
        "    precision = precision_score(y_res, predictions)\n",
        "    recall = recall_score(y_res, predictions)\n",
        "    average_precision = average_precision_score(y_res, predictions)\n",
        "\n",
        "    avg_auc.append(auc_score)\n",
        "    avg_f1.append(f1)\n",
        "    avg_prec.append(precision)\n",
        "    avg_rec.append(recall)\n",
        "    avg_AP.append(average_precision)\n",
        "\n",
        "\n",
        "  print(f'AVG AUC {np.mean(avg_auc):.3f}')\n",
        "  print(f'AVG F1 {np.mean(avg_f1):.3f}')\n",
        "  print(f'AVG precision {np.mean(avg_prec):.3f}')\n",
        "  print(f'AVG recall {np.mean(avg_rec):.3f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "APg8QzNMNcKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_dict = {\n",
        "    'Situations and scenarios - easy': err_SaS_easy,\n",
        "    'Physical Activities - easy': err_PH_AC_easy,\n",
        "    'Interaction with environment - easy': err_IwE_easy,\n",
        "    'Interaction with environment - hard': err_IwE_hard,\n",
        "    'Locomotion - easy': err_Loc_easy,\n",
        "    'Locomotion - hard': err_Loc_hard,\n",
        "    'Locomotion - very hard': err_Loc_Vhard,\n",
        "    'Human Interaction - easy': err_HI_easy,\n",
        "    'Human Interaction - hard': err_HI_hard\n",
        "}\n"
      ],
      "metadata": {
        "id": "N1rhbDrTNgg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Dictionary of quantile thresholds\n",
        "thresholds = {\n",
        "    'quantile_threshold_99': quantile_threshold_99,\n",
        "    'quantile_threshold_95': quantile_threshold_95,\n",
        "    'quantile_threshold_90': quantile_threshold_90,\n",
        "    'quantile_threshold_85': quantile_threshold_85\n",
        "}\n",
        "\n",
        "\n",
        "for error_list in error_dict:\n",
        "  for threshold in thresholds:\n",
        "      print(f\"List name: {error_list}\")\n",
        "      print(f\"Threshold name: {threshold}\")\n",
        "      multiple_random_sampling(err_NORMAL,error_dict[error_list],thresholds[threshold],limit = 100,precent=0.05)\n",
        "      print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "reXU0n_ZNhpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Heatmaps"
      ],
      "metadata": {
        "id": "7s8h7AToNp38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, average_precision_score, matthews_corrcoef\n",
        "\n",
        "def multiple_random_sampling_heatmap(err_NORMAL, err_LIST, threshold, limit=100, percent=0.05):\n",
        "\n",
        "    avg_auc = []\n",
        "    avg_f1 = []\n",
        "    avg_prec = []\n",
        "    avg_rec = []\n",
        "    avg_AP = []\n",
        "    avg_mcc = []\n",
        "\n",
        "    for N in range(limit):\n",
        "        normal_errors = err_NORMAL\n",
        "        anomaly_errors = err_LIST\n",
        "\n",
        "        normal_errors = np.array(normal_errors, dtype=object)\n",
        "        anomaly_errors = np.array(anomaly_errors, dtype=object)\n",
        "\n",
        "        normal_labels = np.zeros(len(normal_errors))\n",
        "        anomaly_labels = np.ones(len(anomaly_errors))\n",
        "\n",
        "        errors = np.concatenate((normal_errors, anomaly_errors))\n",
        "        labels = np.concatenate((normal_labels, anomaly_labels))\n",
        "\n",
        "        df = pd.DataFrame({'errors': errors, 'labels': labels})\n",
        "\n",
        "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "        X_res, y_res = undersample.fit_resample(df[['errors']], df['labels'])\n",
        "\n",
        "        X_res_list = X_res.values.tolist()\n",
        "        X_res_flat = [item for sublist in X_res_list for item in sublist]\n",
        "\n",
        "        predictions = check_against_thresh_pred(X_res_flat, threshold, percent)\n",
        "\n",
        "        auc_score = roc_auc_score(y_res, predictions)\n",
        "        f1 = f1_score(y_res, predictions)\n",
        "        precision = precision_score(y_res, predictions, zero_division=0)\n",
        "        recall = recall_score(y_res, predictions)\n",
        "        average_precision = average_precision_score(y_res, predictions)\n",
        "        mcc = matthews_corrcoef(y_res, predictions)\n",
        "\n",
        "        avg_auc.append(auc_score)\n",
        "        avg_f1.append(f1)\n",
        "        avg_prec.append(precision)\n",
        "        avg_rec.append(recall)\n",
        "        avg_AP.append(average_precision)\n",
        "        avg_mcc.append(mcc)\n",
        "\n",
        "    return avg_auc, avg_f1, avg_prec, avg_rec, avg_AP, avg_mcc\n"
      ],
      "metadata": {
        "id": "y1YY-qqxNr-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, average_precision_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "percentages = [0.01]\n",
        "percentages_range= np.arange(0.05,0.50,0.05)\n",
        "percentages.extend(percentages_range)\n",
        "xticklabels = ['{:.2f}'.format(val) for val in percentages]\n",
        "yticklabels = list(np.arange(50, 100, 5))+[99]\n",
        "yticklabels = ['{}th'.format(val) for val in yticklabels]\n",
        "\n",
        "def calc_results(err_NORMAL,err_LIST):\n",
        "  X_res_flat = [item for sublist in err_NORMAL for item in sublist]\n",
        "\n",
        "  percentile_range = np.arange(50, 100, 5)\n",
        "  percentiles = np.append(percentile_range, 99)\n",
        "  thresholds = np.percentile(X_res_flat, percentiles)\n",
        "\n",
        "  percentages = [0.01]\n",
        "  percentages_range= np.arange(0.05,0.50,0.05)\n",
        "  percentages.extend(percentages_range)\n",
        "\n",
        "  # Create empty arrays to collect the data\n",
        "  results_auc = np.zeros((len(thresholds), len(percentages)))\n",
        "  results_f1 = np.zeros((len(thresholds), len(percentages)))\n",
        "  results_prec = np.zeros((len(thresholds), len(percentages)))\n",
        "  results_rec = np.zeros((len(thresholds), len(percentages)))\n",
        "  results_AP = np.zeros((len(thresholds), len(percentages)))\n",
        "  results_MCC = np.zeros((len(thresholds), len(percentages)))\n",
        "\n",
        "  # Loop through thresholds and percentages\n",
        "  for i, threshold in enumerate(thresholds):\n",
        "      for j, percent in enumerate(percentages):\n",
        "          avg_auc, avg_f1, avg_prec, avg_rec, avg_AP,avg_mcc = multiple_random_sampling_heatmap(err_NORMAL, err_LIST, threshold, percent=percent,limit=50)\n",
        "          results_auc[i, j] = np.mean(avg_auc)\n",
        "          results_f1[i, j] = np.mean(avg_f1)\n",
        "          results_prec[i, j] = np.mean(avg_prec)\n",
        "          results_rec[i, j] = np.mean(avg_rec)\n",
        "          results_AP[i, j] = np.mean(avg_AP)\n",
        "          results_MCC[i,j] = np.mean(avg_mcc)\n",
        "  return results_auc,results_f1,results_prec,results_rec,results_AP,results_MCC\n"
      ],
      "metadata": {
        "id": "f1v4rOd8N2UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_heatmaps(results_auc,results_f1,results_prec,results_rec,results_AP,results_MCC,dataset_name):\n",
        "  metrics = ['AUC', 'F1', 'Precision', 'Recall', 'Average Precision','Matthews Correlation Coefficient']\n",
        "  results = {\n",
        "      'AUC': results_auc,\n",
        "      'F1': results_f1,\n",
        "      'Precision': results_prec,\n",
        "      'Recall': results_rec,\n",
        "      'Average Precision': results_AP ,\n",
        "      'Matthews Correlation Coefficient': results_MCC\n",
        "  }\n",
        "\n",
        "  metric_pairs = [('AUC', 'F1'), ('Precision', 'Recall'),('Average Precision','Matthews Correlation Coefficient')]\n",
        "\n",
        "\n",
        "  for metric1, metric2 in metric_pairs:\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "      # Plot the first heatmap (metric1)\n",
        "      sns.heatmap(results[metric1], annot=True, fmt='.3f', xticklabels=xticklabels, yticklabels=yticklabels, cbar=False, ax=ax[0], cmap=\"viridis\", linewidths=0.5, linecolor=\"gray\")\n",
        "      ax[0].set_title(f'{metric1} Heatmap')\n",
        "      ax[0].set_xlabel('Percentage')\n",
        "      ax[0].set_ylabel('Threshold')\n",
        "      ax[0].tick_params(axis='y', rotation=0)\n",
        "\n",
        "\n",
        "      # Plot the second heatmap (metric2)\n",
        "      sns.heatmap(results[metric2], annot=True, fmt='.3f', xticklabels=xticklabels, yticklabels=yticklabels, cbar=False, ax=ax[1], cmap=\"viridis\", linewidths=0.5, linecolor=\"gray\")\n",
        "      ax[1].set_title(f'{metric2} Heatmap')\n",
        "      ax[1].set_xlabel('Percentage')\n",
        "      ax[1].set_ylabel('Threshold')\n",
        "      ax[1].tick_params(axis='y', rotation=0)\n",
        "\n",
        "      # Add title\n",
        "      fig.suptitle(f'{dataset_name}', fontsize=16)\n",
        "\n",
        "\n",
        "      # Adjust spacing between subplots\n",
        "      plt.tight_layout()\n",
        "\n",
        "      plt.savefig(f'/content/drive/MyDrive/FFT_C_VAE_HEATMAPS/{metric1}_{metric2}_{dataset_name}_heatmaps.png')\n",
        "      #plt.show()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "sne7I1XeN7yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for error_list in error_dict:\n",
        "  results_auc,results_f1,results_prec,results_rec,results_AP,results_MCC = calc_results(err_NORMAL,error_dict[error_list])\n",
        "  draw_heatmaps(results_auc,results_f1,results_prec,results_rec,results_AP,results_MCC,error_list)"
      ],
      "metadata": {
        "id": "F0sQHK27N99b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "metrics = ['AUC', 'F1', 'Precision', 'Recall', 'Average Precision']\n",
        "results = {\n",
        "    'AUC': results_auc,\n",
        "    'F1': results_f1,\n",
        "    'Precision': results_prec,\n",
        "    'Recall': results_rec,\n",
        "    'Average Precision': results_AP\n",
        "}\n",
        "percentages = [0.01] + list(np.arange(0.05, 0.45, 0.05))\n",
        "\n",
        "# Define pairs of metrics\n",
        "metric_pairs = [('AUC', 'F1'), ('Precision', 'Recall')]\n",
        "\n",
        "# Create and save separate pictures for each pair of heatmaps\n",
        "for metric1, metric2 in metric_pairs:\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))  # Side-by-side\n",
        "\n",
        "    # Plot the first heatmap\n",
        "    sns.heatmap(results[metric1], annot=True, fmt='.3f', xticklabels=xticklabels, yticklabels=yticklabels, cbar=False, ax=ax[0], cmap=\"viridis\", linewidths=0.5, linecolor=\"gray\")\n",
        "    ax[0].set_title(f'{metric1} Heatmap')\n",
        "    ax[0].set_xlabel('Percentage')\n",
        "    ax[0].set_ylabel('Threshold')\n",
        "    ax[0].tick_params(axis='y', rotation=0)\n",
        "\n",
        "\n",
        "\n",
        "    # Plot the second heatmap\n",
        "    sns.heatmap(results[metric2], annot=True, fmt='.3f', xticklabels=xticklabels, yticklabels=yticklabels, cbar=False, ax=ax[1], cmap=\"viridis\", linewidths=0.5, linecolor=\"gray\")\n",
        "    ax[1].set_title(f'{metric2} Heatmap')\n",
        "    ax[1].set_xlabel('Percentage')\n",
        "    ax[1].set_ylabel('Threshold')\n",
        "    ax[1].tick_params(axis='y', rotation=0)\n",
        "\n",
        "    # Add title\n",
        "    fig.suptitle('Comparison of Metric Pairs', fontsize=16)\n",
        "\n",
        "\n",
        "    # Adjust spacing\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig(f'{metric1}_{metric2}_heatmaps.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xNW1DTaFOC8u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}